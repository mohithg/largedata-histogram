{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from scipy.stats import entropy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = 'dmm-microbench'\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=\"AKIASVDNFDSGZYUVLQED\", aws_secret_access_key=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "def download_s3_file(file_name, destination_file_name):\n",
    "    s3.download_file(Bucket=S3_BUCKET, Key=file_name, Filename=destination_file_name)\n",
    "\n",
    "def get_content(file_name, expression):\n",
    "    return s3.select_object_content(\n",
    "        Bucket=S3_BUCKET,\n",
    "        Key=file_name,\n",
    "        ExpressionType='SQL',\n",
    "        Expression=expression,\n",
    "        InputSerialization={'CSV': {\"FileHeaderInfo\": \"Use\"}},\n",
    "        OutputSerialization={'CSV': {}},\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_data_to_df(data, record_header):\n",
    "    for event in data['Payload']:\n",
    "        if 'Records' in event:\n",
    "            record_header.append(event['Records']['Payload'])\n",
    "    csv_content = ''.join(r.decode('utf-8').replace(\"\\r\", \"\") for r in record_header)\n",
    "    csv_pd = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "    print('\\n##################################')\n",
    "    print(f\"Length of dataframe: {len(csv_pd)}\")\n",
    "    print(f\"Memory usage of dataframe: \\n {csv_pd.info(memory_usage='deep')}\")\n",
    "    print('\\n##################################')\n",
    "\n",
    "    return pd.DataFrame(csv_pd)\n",
    "\n",
    "def read_dask_csv(file_name):\n",
    "    import dask.dataframe as dd\n",
    "    dd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1,9):\n",
    "    download_s3_file(f\"yellow_tripdata_2019-0{i}.csv\", f\"yellow_tripdata_2019-0{i}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask[complete]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/1a/c7caa87b758a99d1feada7a9f89ffc1d86453d05733668f20161f5489835/dask-2.20.0-py3-none-any.whl (826kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/anaconda/lib/python3.6/site-packages (from dask[complete]) (5.1.2)\n",
      "Collecting distributed>=2.0; extra == \"complete\" (from dask[complete])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/9b7a543349fe9a3ff1974cc329aa4f4affca6fd723e1bd3a3a65ace0d4f6/distributed-2.20.0-py3-none-any.whl (644kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 22.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting partd>=0.3.10; extra == \"complete\" (from dask[complete])\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/68dbe731c9c067655bff1eca5b7d40c20ca4b23fd5ec9f3d17e201a6f36b/partd-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=0.2.2; extra == \"complete\" in /usr/local/anaconda/lib/python3.6/site-packages (from dask[complete]) (0.5.3)\n",
      "Collecting fsspec>=0.6.0; extra == \"complete\" (from dask[complete])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/31/f27a81686b2f1b2f6776bd5db10efc7d88f28a50e8888f55409ef6501a50/fsspec-0.7.4-py3-none-any.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 25.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bokeh>=1.0.0; extra == \"complete\" (from dask[complete])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/d9/7fceb4da358a0cda9f080ac12c5cd46ff2595afbe461f369000524b2881a/bokeh-2.1.1.tar.gz (19.3MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3MB 26.3MB/s eta 0:00:01     |███████████████████████████▋    | 16.7MB 26.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.23.0; extra == \"complete\" in /usr/local/anaconda/lib/python3.6/site-packages (from dask[complete]) (0.23.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.2; extra == \"complete\" in /usr/local/anaconda/lib/python3.6/site-packages (from dask[complete]) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.0; extra == \"complete\" in /usr/local/anaconda/lib/python3.6/site-packages (from dask[complete]) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (0.1.3)\n",
      "Collecting tblib>=1.6.0 (from distributed>=2.0; extra == \"complete\"->dask[complete])\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/de/dca3e651ca62e59c08d324f4a51467fa4b8cbeaafb883b5e83720b4d4a47/tblib-1.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (5.4.5)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (1.5.10)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (41.2.0)\n",
      "Collecting contextvars; python_version < \"3.7\" (from distributed>=2.0; extra == \"complete\"->dask[complete])\n",
      "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
      "Collecting msgpack>=0.6.0 (from distributed>=2.0; extra == \"complete\"->dask[complete])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/35/33aa1af0700d21beabdf74373f31c52c048be8ee082f98edbc37ba3ae956/msgpack-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (274kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 65.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tornado>=5; python_version < \"3.8\" in /usr/local/anaconda/lib/python3.6/site-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: locket in /usr/local/anaconda/lib/python3.6/site-packages (from partd>=0.3.10; extra == \"complete\"->dask[complete]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/anaconda/lib/python3.6/site-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.7 in /usr/local/anaconda/lib/python3.6/site-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.0 in /usr/local/anaconda/lib/python3.6/site-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (6.1.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=16.8 in /usr/local/anaconda/lib/python3.6/site-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (17.1)\n",
      "Requirement already satisfied, skipping upgrade: typing_extensions>=3.7.4 in /usr/local/anaconda/lib/python3.6/site-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (3.7.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/anaconda/lib/python3.6/site-packages (from pandas>=0.23.0; extra == \"complete\"->dask[complete]) (2018.4)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/anaconda/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]) (1.0.0)\n",
      "Collecting immutables>=0.9 (from contextvars; python_version < \"3.7\"->distributed>=2.0; extra == \"complete\"->dask[complete])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 49.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/anaconda/lib/python3.6/site-packages (from python-dateutil>=2.1->bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/anaconda/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/anaconda/lib/python3.6/site-packages (from packaging>=16.8->bokeh>=1.0.0; extra == \"complete\"->dask[complete]) (2.2.0)\n",
      "Building wheels for collected packages: bokeh, contextvars\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.1.1-cp36-none-any.whl size=9257187 sha256=b044f5408d6f61305e86551661c32eb1409f2257b19c552b701eb9d11d7bde39\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/be/22/78/21314fd130a51b17e546e8743780ec61f2a52cfd5b851a2800\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7668 sha256=628f52418c6fdeae61c44bd4567670cebb729beb2c667e597a5d2fe1dd3db9dc\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
      "Successfully built bokeh contextvars\n",
      "\u001b[31mERROR: distributed 2.20.0 has requirement cloudpickle>=1.3.0, but you'll have cloudpickle 0.5.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tblib, immutables, contextvars, msgpack, distributed, partd, fsspec, bokeh, dask\n",
      "  Found existing installation: tblib 1.3.2\n",
      "    Uninstalling tblib-1.3.2:\n",
      "      Successfully uninstalled tblib-1.3.2\n",
      "  Found existing installation: distributed 1.21.8\n",
      "    Uninstalling distributed-1.21.8:\n",
      "      Successfully uninstalled distributed-1.21.8\n",
      "  Found existing installation: partd 0.3.8\n",
      "    Uninstalling partd-0.3.8:\n",
      "      Successfully uninstalled partd-0.3.8\n",
      "  Found existing installation: bokeh 0.12.16\n",
      "    Uninstalling bokeh-0.12.16:\n",
      "      Successfully uninstalled bokeh-0.12.16\n",
      "  Found existing installation: dask 0.17.5\n",
      "    Uninstalling dask-0.17.5:\n",
      "      Successfully uninstalled dask-0.17.5\n",
      "Successfully installed bokeh-2.1.1 contextvars-2.4 dask-2.20.0 distributed-2.20.0 fsspec-0.7.4 immutables-0.14 msgpack-1.0.0 partd-1.1.0 tblib-1.6.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"dask[complete]\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:35341</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>7</li>\n",
       "  <li><b>Cores: </b>7</li>\n",
       "  <li><b>Memory: </b>30.06 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35341' processes=7 threads=7, memory=30.06 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client,LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/e4/b8fc59248399d2482b39340ec9be4bb2493846ac23641b43115a7e5cd675/s3fs-0.4.2-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: botocore>=1.12.91 in /usr/local/anaconda/lib/python3.6/site-packages (from s3fs) (1.12.230)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0 in /usr/local/anaconda/lib/python3.6/site-packages (from s3fs) (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/anaconda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.25.3)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/anaconda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/anaconda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/anaconda/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/anaconda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore>=1.12.91->s3fs) (1.12.0)\n",
      "Installing collected packages: s3fs\n",
      "Successfully installed s3fs-0.4.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install s3fs --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 500 ms, sys: 68 ms, total: 568 ms\n",
      "Wall time: 4.59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID_10</th>\n",
       "      <th>tpep_10pickup_10datetime_10</th>\n",
       "      <th>tpep_10dropoff_10datetime_10</th>\n",
       "      <th>passenger_10count_10</th>\n",
       "      <th>trip_10distance_10</th>\n",
       "      <th>RatecodeID_10</th>\n",
       "      <th>store_10and_10fwd_10flag_10</th>\n",
       "      <th>PULocationID_10</th>\n",
       "      <th>DOLocationID_10</th>\n",
       "      <th>payment_10type_10</th>\n",
       "      <th>...</th>\n",
       "      <th>PULocationID_1</th>\n",
       "      <th>DOLocationID_1</th>\n",
       "      <th>payment_1type_1</th>\n",
       "      <th>fare_1amount_1</th>\n",
       "      <th>extra_1</th>\n",
       "      <th>mta_1tax_1</th>\n",
       "      <th>tip_1amount_1</th>\n",
       "      <th>tolls_1amount_1</th>\n",
       "      <th>improvement_1surcharge_1</th>\n",
       "      <th>total_1amount_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>12/13/2018 10:18:24 PM</td>\n",
       "      <td>12/13/2018 10:39:31 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12/13/2018 10:41:23 PM</td>\n",
       "      <td>12/13/2018 10:47:10 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12/13/2018 10:48:52 PM</td>\n",
       "      <td>12/13/2018 11:20:13 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12/13/2018 10:09:31 PM</td>\n",
       "      <td>12/13/2018 10:14:42 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>12/13/2018 10:32:06 PM</td>\n",
       "      <td>12/13/2018 10:51:36 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID_10 tpep_10pickup_10datetime_10 tpep_10dropoff_10datetime_10  \\\n",
       "0            2      12/13/2018 10:18:24 PM       12/13/2018 10:39:31 PM   \n",
       "1            2      12/13/2018 10:41:23 PM       12/13/2018 10:47:10 PM   \n",
       "2            2      12/13/2018 10:48:52 PM       12/13/2018 11:20:13 PM   \n",
       "3            2      12/13/2018 10:09:31 PM       12/13/2018 10:14:42 PM   \n",
       "4            2      12/13/2018 10:32:06 PM       12/13/2018 10:51:36 PM   \n",
       "\n",
       "   passenger_10count_10  trip_10distance_10  RatecodeID_10  \\\n",
       "0                     1                2.41              1   \n",
       "1                     1                0.73              1   \n",
       "2                     1                6.54              1   \n",
       "3                     1                1.00              1   \n",
       "4                     1                2.66              1   \n",
       "\n",
       "  store_10and_10fwd_10flag_10  PULocationID_10  DOLocationID_10  \\\n",
       "0                           N               48              107   \n",
       "1                           N              107               79   \n",
       "2                           N               79              188   \n",
       "3                           N              238              142   \n",
       "4                           N              143              238   \n",
       "\n",
       "   payment_10type_10       ...        PULocationID_1  DOLocationID_1  \\\n",
       "0                  1       ...                    48             107   \n",
       "1                  1       ...                   107              79   \n",
       "2                  1       ...                    79             188   \n",
       "3                  2       ...                   238             142   \n",
       "4                  1       ...                   143             238   \n",
       "\n",
       "   payment_1type_1  fare_1amount_1  extra_1  mta_1tax_1  tip_1amount_1  \\\n",
       "0                1            14.5      0.5         0.5           3.00   \n",
       "1                1             5.5      0.5         0.5           1.36   \n",
       "2                1            24.5      0.5         0.5           4.00   \n",
       "3                2             6.0      0.5         0.5           0.00   \n",
       "4                1            13.5      0.5         0.5           2.96   \n",
       "\n",
       "   tolls_1amount_1 improvement_1surcharge_1 total_1amount_1  \n",
       "0              0.0                      0.3           18.80  \n",
       "1              0.0                      0.3            8.16  \n",
       "2              0.0                      0.3           29.80  \n",
       "3              0.0                      0.3            7.30  \n",
       "4              0.0                      0.3           17.76  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#import dask.dataframe as dd\n",
    "#dask_df = dd.read_csv(f\"2Mn_200Cols.csv\", assume_missing=True, blocksize=10 * 1024 * 1024)\n",
    "\n",
    "#Read the file directly from S3\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "large_data = \"s3://dmm-microbench/120Mn_200Cols_header.csv\"\n",
    "medium_data = \"s3://dmm-microbench/10Mn_200Cols_header.csv\"\n",
    "small_data = \"s3://dmm-microbench/2Mn_200Cols.csv\"\n",
    "\n",
    "dask_df = dd.read_csv(large_data ,\\\n",
    "                      storage_options = {'key': 'AKIAIJX332EW4ZR5DZHA', \\\n",
    "                                         'secret': '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'})\n",
    "dask_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory usage tool\n",
    "memory_usage = dask_df.memory_usage(deep=True).compute()\n",
    "# total memory usage in GB\n",
    "memory_usage.sum() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Read from Domino datasets\n",
    "#dask_df_domino_dataset = dd.read_csv(\"/domino/datasets/local/2Mn_200Cols_NY_Taxi/2Mn_200Cols.csv\")\n",
    "#dask_df_domino_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for local file\n",
    "columns = []\n",
    "for i in range(1,13):\n",
    "    columns.append(f\"passenger_{i}count{i}\")\n",
    "    columns.append(f\"trip_{i}distance_{i}\")\n",
    "    columns.append(f\"fare_{i}amount_{i}\")\n",
    "    columns.append(f\"extra_{i}\")\n",
    "    columns.append(f\"mta_{i}tax_{i}\")\n",
    "    columns.append(f\"tip_{i}amount_{i}\")\n",
    "    columns.append(f\"tolls_{i}amount_{i}\")\n",
    "    columns.append(f\"improvement_{i}surcharge_{i}\")\n",
    "    columns.append(f\"total_{i}amount_{i}\")\n",
    "    columns.append(f\"congestion_{i}surcharge_{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"congestion_surcharge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask.array as da\n",
    "import dask\n",
    "def histogram_compute(col):\n",
    "    try:\n",
    "        col_data = dask_df[col]\n",
    "        h, bins = da.histogram(col_data, bins=100, range=[col_data.min(), col_data.max()])\n",
    "        return (h, bins)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0,0)\n",
    "all_computations = map(histogram_compute, columns)\n",
    "try:\n",
    "    list_of_col_hists = dask.compute(all_computations)\n",
    "    for item in list_of_col_hists:\n",
    "        print(item)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute histograms for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"store_and_fwd_flag\", \"payment_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "for i in range(1,10):\n",
    "    categorical_columns.append(f\"store_{i}and_{i}fwd_{i}flag_{i}\")\n",
    "    categorical_columns.append(f\"payment_{i}type_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask_df.dropna().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "def histogram_compute(col):\n",
    "    col_data = dask_df[col]\n",
    "    bins = col_data.unique()\n",
    "    counts = col_data.value_counts()\n",
    "    return (bins, counts)    \n",
    "all_computations = map(histogram_compute, categorical_columns)\n",
    "list_of_col_hists = dask.compute(all_computations)\n",
    "for item in list_of_col_hists:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to get data types, summary statistics, autobin and get 1d-distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.09 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VendorID_10                       int64\n",
       "tpep_10pickup_10datetime_10      object\n",
       "tpep_10dropoff_10datetime_10     object\n",
       "passenger_10count_10              int64\n",
       "trip_10distance_10              float64\n",
       "RatecodeID_10                     int64\n",
       "store_10and_10fwd_10flag_10      object\n",
       "PULocationID_10                   int64\n",
       "DOLocationID_10                   int64\n",
       "payment_10type_10                 int64\n",
       "fare_10amount_10                float64\n",
       "extra_10                        float64\n",
       "mta_10tax_10                    float64\n",
       "tip_10amount_10                 float64\n",
       "tolls_10amount_10               float64\n",
       "improvement_10surcharge_10      float64\n",
       "total_10amount_10               float64\n",
       "VendorID_11                       int64\n",
       "tpep_11pickup_11datetime_11      object\n",
       "tpep_11dropoff_11datetime_11     object\n",
       "passenger_11count_11              int64\n",
       "trip_11distance_11              float64\n",
       "RatecodeID_11                     int64\n",
       "store_11and_11fwd_11flag_11      object\n",
       "PULocationID_11                   int64\n",
       "DOLocationID_11                   int64\n",
       "payment_11type_11                 int64\n",
       "fare_11amount_11                float64\n",
       "extra_11                        float64\n",
       "mta_11tax_11                    float64\n",
       "                                 ...   \n",
       "trip_9distance_9                float64\n",
       "RatecodeID_9                      int64\n",
       "store_9and_9fwd_9flag_9          object\n",
       "PULocationID_9                    int64\n",
       "DOLocationID_9                    int64\n",
       "payment_9type_9                   int64\n",
       "fare_9amount_9                  float64\n",
       "extra_9                         float64\n",
       "mta_9tax_9                      float64\n",
       "tip_9amount_9                   float64\n",
       "tolls_9amount_9                 float64\n",
       "improvement_9surcharge_9        float64\n",
       "total_9amount_9                 float64\n",
       "VendorID_1                        int64\n",
       "tpep_1pickup_1datetime_1         object\n",
       "tpep_1dropoff_1datetime_1        object\n",
       "passenger_1count_1                int64\n",
       "trip_1distance_1                float64\n",
       "RatecodeID_1                      int64\n",
       "store_1and_1fwd_1flag_1          object\n",
       "PULocationID_1                    int64\n",
       "DOLocationID_1                    int64\n",
       "payment_1type_1                   int64\n",
       "fare_1amount_1                  float64\n",
       "extra_1                         float64\n",
       "mta_1tax_1                      float64\n",
       "tip_1amount_1                   float64\n",
       "tolls_1amount_1                 float64\n",
       "improvement_1surcharge_1        float64\n",
       "total_1amount_1                 float64\n",
       "Length: 204, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Get the datatypes\n",
    "df_dtypes = dask_df.dtypes\n",
    "df_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VendorID_10                     int64\n",
       "passenger_10count_10            int64\n",
       "trip_10distance_10            float64\n",
       "RatecodeID_10                   int64\n",
       "PULocationID_10                 int64\n",
       "DOLocationID_10                 int64\n",
       "payment_10type_10               int64\n",
       "fare_10amount_10              float64\n",
       "extra_10                      float64\n",
       "mta_10tax_10                  float64\n",
       "tip_10amount_10               float64\n",
       "tolls_10amount_10             float64\n",
       "improvement_10surcharge_10    float64\n",
       "total_10amount_10             float64\n",
       "VendorID_11                     int64\n",
       "passenger_11count_11            int64\n",
       "trip_11distance_11            float64\n",
       "RatecodeID_11                   int64\n",
       "PULocationID_11                 int64\n",
       "DOLocationID_11                 int64\n",
       "payment_11type_11               int64\n",
       "fare_11amount_11              float64\n",
       "extra_11                      float64\n",
       "mta_11tax_11                  float64\n",
       "tip_11amount_11               float64\n",
       "tolls_11amount_11             float64\n",
       "improvement_11surcharge_11    float64\n",
       "total_11amount_11             float64\n",
       "VendorID_12                     int64\n",
       "passenger_12count_12            int64\n",
       "                               ...   \n",
       "improvement_8surcharge_8      float64\n",
       "total_8amount_8               float64\n",
       "VendorID_9                      int64\n",
       "passenger_9count_9              int64\n",
       "trip_9distance_9              float64\n",
       "RatecodeID_9                    int64\n",
       "PULocationID_9                  int64\n",
       "DOLocationID_9                  int64\n",
       "payment_9type_9                 int64\n",
       "fare_9amount_9                float64\n",
       "extra_9                       float64\n",
       "mta_9tax_9                    float64\n",
       "tip_9amount_9                 float64\n",
       "tolls_9amount_9               float64\n",
       "improvement_9surcharge_9      float64\n",
       "total_9amount_9               float64\n",
       "VendorID_1                      int64\n",
       "passenger_1count_1              int64\n",
       "trip_1distance_1              float64\n",
       "RatecodeID_1                    int64\n",
       "PULocationID_1                  int64\n",
       "DOLocationID_1                  int64\n",
       "payment_1type_1                 int64\n",
       "fare_1amount_1                float64\n",
       "extra_1                       float64\n",
       "mta_1tax_1                    float64\n",
       "tip_1amount_1                 float64\n",
       "tolls_1amount_1               float64\n",
       "improvement_1surcharge_1      float64\n",
       "total_1amount_1               float64\n",
       "Length: 168, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create a Dask dataframe with only numeric data\n",
    "dask_df_numeric = dask_df._get_numeric_data()\n",
    "dask_df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dask\n",
    "# Data statistics ; skipNA is the default\n",
    "\n",
    "data_mean,data_max,data_min,data_std,data_shape = dask.compute(\\\n",
    "                                                                dask_df.mean(),\n",
    "                                                                dask_df.max(),\n",
    "                                                                dask_df.min(),\n",
    "                                                                dask_df.std(),\n",
    "                                                                dask_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 17.2 s, total: 1min 52s\n",
      "Wall time: 18min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask\n",
    "data_shape = dask.compute(dask_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dask's built in describe; faster than doing it one statistic at a time\n",
    "descriptive_statistics = dask_df.describe(percentiles=[.25, .5, .75, .85, .9]).compute()\n",
    "descriptive_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "(\"('read-csv-dataframe--get_numeric_data-0574dc79e253c6c6a31b6e2324d484ee', 1701)\", <Worker 'tcp://127.0.0.1:39875', name: 1, memory: 0, processing: 9000>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2680\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1980\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             )\n\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             return sync(\n\u001b[0;32m--> 832\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m             )\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKilledWorker\u001b[0m: (\"('read-csv-dataframe--get_numeric_data-0574dc79e253c6c6a31b6e2324d484ee', 1701)\", <Worker 'tcp://127.0.0.1:39875', name: 1, memory: 0, processing: 9000>)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the interquartile range for the numeric columns\n",
    "# Apart from data statistics we also need this for the FD estimator\n",
    "\n",
    "#Dont use this when implementing in production, take the values from describe(). Doing this to see how long IQR takes\n",
    "#end to end\n",
    "df_q3, df_q1 = dask.compute(dask_df_numeric.quantile(0.75), dask_df_numeric.quantile(0.25))\n",
    "df_iqr = df_q3 - df_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_iqr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-942561771411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_iqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_iqr' is not defined"
     ]
    }
   ],
   "source": [
    "df_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Sturges estimator (needs to be computed just once as it is only based on the number of samples)\n",
    "\n",
    "# Get the number of rows\n",
    "from math import log2,floor,sqrt\n",
    "n_rows = data_shape[0]\n",
    "\n",
    "#Compute the estimator\n",
    "#Convert to float because FD will be float for all the columns later on\n",
    "sturges_estimator = float(floor(log2(n_rows[0]) + 1))\n",
    "sturges_estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Compute the FD estimator for all the numeric columns\n",
    "import numpy as np\n",
    "\n",
    "fd_estimator_denominator = pow(n_rows[0],1./3.)\n",
    "fd_estimator_denominator\n",
    "fd_estimator = np.ceil(2*(df_iqr/fd_estimator_denominator)) \n",
    "fd_estimator[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Take the max of Sturges and the FD estimator\n",
    "#Creating a new variable for now in order to retain the FD estimator for debugging later\n",
    "import copy\n",
    "\n",
    "nBins = copy.copy(fd_estimator)\n",
    "nBins.loc[nBins < sturges_estimator] = sturges_estimator\n",
    "nBins = nBins.astype(int)\n",
    "nBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Compute the histograms\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "def histogram_compute(col):\n",
    "    try:\n",
    "        col_data = dask_df[col]\n",
    "        h, bins = da.histogram(col_data, bins=nBins[col], range=[col_data.min(), col_data.max()])\n",
    "        return (h, bins)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0,0)\n",
    "all_computations = map(histogram_compute, nBins.index.tolist())\n",
    "try:\n",
    "    list_of_col_hists = dask.compute(all_computations)\n",
    "    for item in list_of_col_hists:\n",
    "           print(item)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
